{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Cell 1 — Path & environment check"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from pathlib import Path\n",
    "\n",
    "# Update this to your actual directory containing copied .pt files\n",
    "PT_DIR = Path(\"/home/stat-jijianxin1997/SCI_GC_OS/pt_file\")\n",
    "\n",
    "print(\"PT_DIR:\", PT_DIR)\n",
    "print(\"Exists:\", PT_DIR.exists())\n",
    "\n",
    "pt_files = sorted([p.name for p in PT_DIR.glob(\"*.pt\")])\n",
    "print(\"Number of .pt files:\", len(pt_files))\n",
    "print(\"First 5 files:\", pt_files[:5])\n",
    "\n",
    "assert PT_DIR.exists(), f\"PT_DIR not found: {PT_DIR}\"\n",
    "assert len(pt_files) > 0, f\"No .pt files found under: {PT_DIR}\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Cell 2 — Sanity check: load one .pt and inspect shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "sample_path = PT_DIR / pt_files[0]\n",
    "print(\"Loading:\", sample_path)\n",
    "\n",
    "x = torch.load(sample_path, map_location=\"cpu\")\n",
    "print(\"Type:\", type(x))\n",
    "\n",
    "if isinstance(x, torch.Tensor):\n",
    "    print(\"Tensor shape:\", tuple(x.shape))\n",
    "    print(\"Dtype:\", x.dtype)\n",
    "else:\n",
    "    # In case the saved object is not a plain tensor\n",
    "    print(\"Loaded object:\", x)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Cell 3 — Build a minimal demo CSV (so the Dataset can run)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "\n",
    "# Use a few .pt files for a minimal, runnable demo\n",
    "demo_pt = pt_files[:4]\n",
    "\n",
    "demo_df = pd.DataFrame({\n",
    "    \"case_id\": [f\"DEMO_{i}\" for i in range(len(demo_pt))],\n",
    "    \"gender\": [\"male\", \"female\", \"male\", \"female\"][:len(demo_pt)],\n",
    "    \"age_at_index\": [60, 55, 70, 49][:len(demo_pt)],\n",
    "    \"label\": [0, 1, 2, 3][:len(demo_pt)],                 # discrete interval label (example)\n",
    "    \"survival_months\": [10.0, 20.0, 5.0, 18.0][:len(demo_pt)],\n",
    "    \"censor\": [0, 1, 0, 1][:len(demo_pt)],                # 0=event, 1=censored (per your loss code)\n",
    "    \"slide_id\": [str([name]) for name in demo_pt],        # IMPORTANT: python list string\n",
    "})\n",
    "\n",
    "demo_csv_path = Path(\"./demo_minimal.csv\")\n",
    "demo_df.to_csv(demo_csv_path, index=False)\n",
    "\n",
    "print(\"Saved demo CSV to:\", demo_csv_path.resolve())\n",
    "demo_df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Cell 4 — Create Dataset + DataLoader (PT mode) with padding mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "\n",
    "# Update import paths to match your repo file names\n",
    "from dataset_position import SwinPrognosisDataset\n",
    "from model_utils import custom_collate_fn\n",
    "\n",
    "load_mode = \"pt\"\n",
    "\n",
    "dataset = SwinPrognosisDataset(\n",
    "    df=str(demo_csv_path),\n",
    "    pt_dir=str(PT_DIR),\n",
    "    load_mode=load_mode\n",
    ")\n",
    "\n",
    "loader = DataLoader(\n",
    "    dataset,\n",
    "    batch_size=2,\n",
    "    shuffle=False,\n",
    "    num_workers=0,  # keep 0 in notebooks for stability\n",
    "    collate_fn=lambda batch: custom_collate_fn(batch, load_mode)\n",
    ")\n",
    "\n",
    "batch = next(iter(loader))\n",
    "print(\"Batch tuple length:\", len(batch))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Cell 5 — Inspect batch tensors (features + mask)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(patient, gender, age, label, sur_time, censor, feature, coords, num_patches, mask) = batch\n",
    "\n",
    "print(\"patient:\", patient)\n",
    "print(\"gender:\", gender.shape, gender.dtype, gender)\n",
    "print(\"age:\", age.shape, age.dtype, age)\n",
    "print(\"label:\", label.shape, label.dtype, label)\n",
    "print(\"sur_time:\", sur_time.shape, sur_time.dtype, sur_time)\n",
    "print(\"censor:\", censor.shape, censor.dtype, censor)\n",
    "\n",
    "print(\"feature:\", feature.shape, feature.dtype)  # (B, max_patches, D)\n",
    "print(\"mask:\", mask.shape, mask.dtype)           # (B, max_patches)\n",
    "print(\"num_patches:\", num_patches)\n",
    "print(\"coords is None:\", coords is None)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Cell 6 — Forward pass with Transformer + compute CombinedSurvLoss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "from transformer_context import Transformer\n",
    "from loss_func import CombinedSurvLoss\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(\"Device:\", device)\n",
    "\n",
    "# Adjust these to match your actual feature dimension and discretization (num_classes)\n",
    "model_params = {\n",
    "    \"num_classes\": 4,\n",
    "    \"input_dim\": 1024,   # UNI features are typically 1024-d\n",
    "    \"dim\": 512,\n",
    "    \"depth\": 1,\n",
    "    \"heads\": 2,\n",
    "    \"mlp_dim\": 128,\n",
    "    \"pool\": \"cls\",\n",
    "    \"dim_head\": 128,\n",
    "    \"dropout\": 0.3,\n",
    "    \"emb_dropout\": 0.3,\n",
    "}\n",
    "\n",
    "criterion_params = {\"alpha\": 0.5}\n",
    "\n",
    "model = Transformer(**model_params).to(device)\n",
    "criterion = CombinedSurvLoss(**criterion_params).to(device)\n",
    "\n",
    "model.eval()\n",
    "\n",
    "feature = feature.to(device)\n",
    "mask = mask.to(device)\n",
    "age = age.to(device)\n",
    "gender = gender.to(device)\n",
    "label = label.to(device)\n",
    "sur_time = sur_time.to(device)\n",
    "censor = censor.to(device)\n",
    "\n",
    "with torch.no_grad():\n",
    "    # IMPORTANT: Transformer.forward signature is (x, age, gender, mask=None)\n",
    "    outputs = model(feature, age, gender, mask)\n",
    "\n",
    "loss = criterion(outputs=outputs, y=label, t=sur_time, c=censor)\n",
    "\n",
    "print(\"outputs shape:\", tuple(outputs.shape))\n",
    "print(\"loss:\", float(loss))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Cell 7 (optional) — Quick check: mask correctness"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# For each sample, valid patches should sum to num_patches\n",
    "mask_sums = mask.sum(dim=1).cpu()\n",
    "print(\"mask sums:\", mask_sums.tolist())\n",
    "print(\"num_patches:\", num_patches.cpu().tolist())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "clam",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
